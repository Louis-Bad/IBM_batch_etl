{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f2f5580-fa44-461b-bc12-9939ce3f124b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24f9c6-2e1b-4624-8a7a-9c92208e3149",
   "metadata": {},
   "source": [
    "The below script will extract data from multiple sources and file types (csv, json, xml) before performing a simple cleaning tasks and finally outputting a single csv file. The csv output file will be a collation of all the data ingested, post the simple cleaning transformation. <br>\n",
    "Of course, this was just a fun evening project and the code has not been designed for any kind of commercial application.\n",
    "<br><br>\n",
    "The data is a very simple dataset comprising of a handful of people and a log of their names, height and weight. In the data file holding each of the datasets exists a three duplicates of the same data. Again, the data itself is not important, more so that I had a simple collection of multiple sources of data to play around with. \n",
    "<br><br>\n",
    "I have also taken a very 'functional programming' approach here where all of the operations have been broken down into smaller modularised functions that will then be called within other functions representing the extract, transform and load operations of an automated ETL pipeline. This can (or will be) further generalised into a final single function that will take an arguement of one file path, directing the script to the directory containing the many differing sources of data. This final function will then output a single collation of these data sources as one .csv file and an accompanying etl_process_log.text file containing the details of each stage of the etl process and that stage's corresponding timestamp.\n",
    "<br><br>\n",
    "For the sake of true automation, the below code can easily be copied into a script text file and executed via an OS's automated task command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b3248-ccca-4cda-98b3-9d0a3b47bc23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8c661b-7e18-4bab-8a01-7fece69f1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2674442-f2e7-4ee4-b319-d44d9aac8c4a",
   "metadata": {},
   "source": [
    "# Building The Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dad3c8d-4b07-49db-893d-a79025c70693",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ab48a0-8afc-47fe-8d43-8e14516a4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in a csv file\n",
    "'''\n",
    "This function will read in a csv file and output a pandas dataframe object\n",
    "Input: file path\n",
    "Output: pandas object\n",
    "Params: file_to_process\n",
    "'''\n",
    "def extract_from_csv(file_to_process): \n",
    "    col_names = ['Name', 'Height', 'Weight']\n",
    "    dataframe = pd.read_csv(file_to_process) \n",
    "    dataframe.columns = col_names\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to read in multiple csv files\n",
    "'''\n",
    "This function will read in a list of csv files and output a pandas dataframe object\n",
    "Input: iterable list of file paths\n",
    "Output: pandas object\n",
    "Params: path_list\n",
    "'''\n",
    "def multiple_csv(path_list):\n",
    "    df_list = []\n",
    "    for path in path_list:\n",
    "        dataframe = extract_from_csv(path)\n",
    "        df_list.append(dataframe)\n",
    "        \n",
    "    return pd.concat(df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9971556-1dd1-48dc-9061-14a141aeb1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in a json file\n",
    "'''\n",
    "This function will read in a csv file and output a pandas dataframe object\n",
    "Input: file path\n",
    "Output: pandas object\n",
    "Params: file_to_process\n",
    "'''\n",
    "def extract_from_json(file_to_process): \n",
    "    col_names = ['Name', 'Height', 'Weight']\n",
    "    dataframe = pd.read_json(file_to_process, lines=True) \n",
    "    dataframe.columns = col_names\n",
    "    return dataframe \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to read in multiple json files\n",
    "'''\n",
    "This function will read in a list of json files and output a pandas dataframe object\n",
    "Input: iterable list of file paths\n",
    "Output: pandas object\n",
    "Params: path_list\n",
    "'''\n",
    "def multiple_json(path_list):\n",
    "    df_list = []\n",
    "    for path in path_list:\n",
    "        dataframe = extract_from_json(path)\n",
    "        df_list.append(dataframe)\n",
    "        \n",
    "    return pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6075e7-80fc-4e0b-8bb5-7a207c5a3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in an xml file\n",
    "'''\n",
    "This function will read in a csv file and output a pandas dataframe object. This assumes a very specific xml tree schema and is not broadly\n",
    "applicable to any other xml schemas. \n",
    "Input: file path\n",
    "Output: pandas object\n",
    "Params: file_to_process\n",
    "'''\n",
    "def extract_from_xml(file_to_process):\n",
    "    # Create an empty dataframe \n",
    "    col_names = ['Name', 'Height', 'Weight']\n",
    "    dataframe = pd.DataFrame(columns = col_names)\n",
    "    \n",
    "    # Create tree object and acess the root element\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root_element = tree.getroot()\n",
    "    \n",
    "    # Iterate through each child of the root element (in this case this is an individual person)\n",
    "    for child in root_element:\n",
    "        # Accessing name, height and weight of each person\n",
    "        name = child.find('name').text\n",
    "        height = child.find('height').text\n",
    "        weight = child.find('weight').text\n",
    "        \n",
    "        # Appending new row of data to existing dataframe\n",
    "        dataframe.loc[len(dataframe), :] = [name, height, weight]\n",
    "    \n",
    "    return dataframe\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Function to read in multiple xml files\n",
    "'''\n",
    "This function will read in a list of xml files and output a pandas dataframe object\n",
    "Input: iterable list of file paths\n",
    "Output: pandas object\n",
    "Params: path_list\n",
    "'''\n",
    "def multiple_xml(path_list):\n",
    "    df_list = []\n",
    "    for path in path_list:\n",
    "        dataframe = extract_from_xml(path)\n",
    "        df_list.append(dataframe)\n",
    "        \n",
    "    return pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1ae0e75-099a-4774-929e-beb94e970707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to batch ingest multiple files\n",
    "'''\n",
    "This function will take a file path pointing towards a directory (folder) and return a single dataframe object containing a collation of all the\n",
    "data found in that directory, assuming that the file types containing such data are either .csv, .xml or .json\n",
    "Input: directory file path\n",
    "Output: pandas dataframe\n",
    "Params: file_path\n",
    "'''\n",
    "def batch_extract(file_path):\n",
    "    # Creating a list of file paths found in the given directory. One list for each file type\n",
    "    csv_paths = glob.glob(file_path + '*.csv')\n",
    "    json_paths = glob.glob(file_path + '*.json')\n",
    "    xml_paths = glob.glob(file_path + '*.xml')\n",
    "    \n",
    "    # Extract all csv files and return a dataframe\n",
    "    csv_df = multiple_csv(csv_paths)\n",
    "    \n",
    "    # Extract all json files and return a dataframe\n",
    "    json_df = multiple_json(json_paths)\n",
    "    \n",
    "    # Extract all xml files and return a dataframe\n",
    "    xml_df = multiple_xml(xml_paths)\n",
    "    \n",
    "    \n",
    "    return pd.concat([csv_df, json_df, xml_df],ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8243de77-1fdc-4dd7-8c3f-8e1a10187678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>simon</td>\n",
       "      <td>67.90</td>\n",
       "      <td>112.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ivan</td>\n",
       "      <td>67.62</td>\n",
       "      <td>114.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>joe</td>\n",
       "      <td>67.79</td>\n",
       "      <td>144.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tom</td>\n",
       "      <td>69.8</td>\n",
       "      <td>141.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ravi</td>\n",
       "      <td>68.22</td>\n",
       "      <td>142.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ivan</td>\n",
       "      <td>67.62</td>\n",
       "      <td>114.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ajay</td>\n",
       "      <td>71.52</td>\n",
       "      <td>136.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alice</td>\n",
       "      <td>69.4</td>\n",
       "      <td>153.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alex</td>\n",
       "      <td>65.78</td>\n",
       "      <td>112.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ravi</td>\n",
       "      <td>68.22</td>\n",
       "      <td>142.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name Height  Weight\n",
       "35  simon  67.90  112.37\n",
       "38   ivan  67.62  114.14\n",
       "14    joe  67.79   144.3\n",
       "16    tom   69.8  141.49\n",
       "3    ravi  68.22  142.34\n",
       "34   ivan  67.62  114.14\n",
       "1    ajay  71.52  136.49\n",
       "7   alice   69.4  153.03\n",
       "5    alex  65.78  112.99\n",
       "13   ravi  68.22  142.34"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_extract('data/').sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422eba6-f35e-4776-b4b3-97562e0b0056",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Transform Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46ef6c-c2d7-4022-9066-c51de6b7b5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79055877-ad23-443b-8dd5-39e2cfed9b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f2426-20ea-416d-8844-b3e6f1684400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39275981-d160-4f49-9e32-7fb1b1f7e85d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf5a1fb-f713-4dfc-a02c-e9f6f03ca55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728de7d5-29f5-4b60-8caf-bfe23d115b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f28006-4682-4098-8fed-af293789042f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17e3109f-0e3d-45ef-9baa-8b2962381ab9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Process Log Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489d214-40f7-4a3a-add7-48f447eb5aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7ca64-257a-47b2-8982-95dd9a35bc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4ad3d-8758-46f3-89ec-f444f201081c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5150c400-4cc5-4273-8dc2-d484ebc1b2cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Final Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a65b1-f117-4cad-80fc-9f4be450da80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865f869-9974-42cc-992b-e4e75666875f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
