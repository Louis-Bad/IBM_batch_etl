{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f2f5580-fa44-461b-bc12-9939ce3f124b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24f9c6-2e1b-4624-8a7a-9c92208e3149",
   "metadata": {},
   "source": [
    "The below script will extract data from multiple sources and file types (csv, json, xml) before performing simple cleaning tasks and finally outputting a single csv file. The csv output file will be a collation of all the data ingested, post the simple cleaning transformation. <br>\n",
    "Of course, this was just a fun evening project and the code has not been designed for any kind of commercial application.\n",
    "<br><br>\n",
    "The data is a very simple dataset comprising of a handful of people and a log of their names, height and weight. In the data file holding each of the datasets exists three duplicates of the same data. Again, the data itself is not important, more so that I had a simple collection of multiple sources of data to play around with. \n",
    "<br><br>\n",
    "I have also taken a very 'functional programming' approach here, where all of the operations have been broken down into smaller modularised functions that will then be called within other functions representing the extract, transform and load operations of an automated ETL pipeline. This can (or will be) further generalised into a final single function that will take an arguement of one file path, directing the script to the directory containing the many differing sources of data. This final function will then output a single collation of these data sources as one .csv file and an accompanying etl_process_log.text file containing the details of each stage of the etl process and that stage's corresponding timestamp.\n",
    "<br><br>\n",
    "For the sake of true automation, the below code can easily be copied into a script text file and executed via an OS's automated task command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b3248-ccca-4cda-98b3-9d0a3b47bc23",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8c661b-7e18-4bab-8a01-7fece69f1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2674442-f2e7-4ee4-b319-d44d9aac8c4a",
   "metadata": {},
   "source": [
    "# Building The Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dad3c8d-4b07-49db-893d-a79025c70693",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ab48a0-8afc-47fe-8d43-8e14516a4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in a csv file\n",
    "'''\n",
    "This function will read in a csv file and output a pandas dataframe object\n",
    "Input: file path\n",
    "Output: pandas object\n",
    "Params: file_to_process\n",
    "'''\n",
    "def extract_from_csv(file_to_process): \n",
    "    col_names = ['Name', 'Height', 'Weight']\n",
    "    dataframe = pd.read_csv(file_to_process) \n",
    "    dataframe.columns = col_names\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to read in multiple csv files\n",
    "'''\n",
    "This function will read in a list of csv files and output a pandas dataframe object\n",
    "Input: iterable list of file paths\n",
    "Output: pandas object\n",
    "Params: path_list\n",
    "'''\n",
    "def multiple_csv(path_list):\n",
    "    df_list = []\n",
    "    for path in path_list:\n",
    "        dataframe = extract_from_csv(path)\n",
    "        df_list.append(dataframe)\n",
    "        \n",
    "    return pd.concat(df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9971556-1dd1-48dc-9061-14a141aeb1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in a json file\n",
    "'''\n",
    "This function will read in a csv file and output a pandas dataframe object\n",
    "Input: file path\n",
    "Output: pandas object\n",
    "Params: file_to_process\n",
    "'''\n",
    "def extract_from_json(file_to_process): \n",
    "    col_names = ['Name', 'Height', 'Weight']\n",
    "    dataframe = pd.read_json(file_to_process, lines=True) \n",
    "    dataframe.columns = col_names\n",
    "    return dataframe \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to read in multiple json files\n",
    "'''\n",
    "This function will read in a list of json files and output a pandas dataframe object\n",
    "Input: iterable list of file paths\n",
    "Output: pandas object\n",
    "Params: path_list\n",
    "'''\n",
    "def multiple_json(path_list):\n",
    "    df_list = []\n",
    "    for path in path_list:\n",
    "        dataframe = extract_from_json(path)\n",
    "        df_list.append(dataframe)\n",
    "        \n",
    "    return pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6075e7-80fc-4e0b-8bb5-7a207c5a3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in an xml file\n",
    "'''\n",
    "This function will read in a csv file and output a pandas dataframe object. This assumes a very specific xml tree schema and is not broadly\n",
    "applicable to any other xml schemas. \n",
    "Input: file path\n",
    "Output: pandas object\n",
    "Params: file_to_process\n",
    "'''\n",
    "def extract_from_xml(file_to_process):\n",
    "    # Create an empty dataframe \n",
    "    col_names = ['Name', 'Height', 'Weight']\n",
    "    dataframe = pd.DataFrame(columns = col_names)\n",
    "    \n",
    "    # Create tree object and acess the root element\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root_element = tree.getroot()\n",
    "    \n",
    "    # Iterate through each child of the root element (in this case this is an individual person)\n",
    "    for child in root_element:\n",
    "        # Accessing name, height and weight of each person\n",
    "        name = child.find('name').text\n",
    "        height = child.find('height').text\n",
    "        weight = child.find('weight').text\n",
    "        \n",
    "        # Appending new row of data to existing dataframe\n",
    "        dataframe.loc[len(dataframe), :] = [name, height, weight]\n",
    "    \n",
    "    return dataframe\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Function to read in multiple xml files\n",
    "'''\n",
    "This function will read in a list of xml files and output a pandas dataframe object\n",
    "Input: iterable list of file paths\n",
    "Output: pandas object\n",
    "Params: path_list\n",
    "'''\n",
    "def multiple_xml(path_list):\n",
    "    df_list = []\n",
    "    for path in path_list:\n",
    "        dataframe = extract_from_xml(path)\n",
    "        df_list.append(dataframe)\n",
    "        \n",
    "    return pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1ae0e75-099a-4774-929e-beb94e970707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to batch ingest multiple files\n",
    "'''\n",
    "This function will take a file path pointing towards a directory (folder) and return a single dataframe object containing a collation of all the\n",
    "data found in that directory, assuming that the file types containing such data are either .csv, .xml or .json\n",
    "Input: directory file path\n",
    "Output: pandas dataframe\n",
    "Params: file_path\n",
    "'''\n",
    "def batch_extract(file_path):\n",
    "    # Creating a list of file paths found in the given directory. One list for each file type\n",
    "    csv_paths = glob.glob(file_path + '*.csv')\n",
    "    json_paths = glob.glob(file_path + '*.json')\n",
    "    xml_paths = glob.glob(file_path + '*.xml')\n",
    "    \n",
    "    # Extract all csv files and return a dataframe\n",
    "    csv_df = multiple_csv(csv_paths)\n",
    "    \n",
    "    # Extract all json files and return a dataframe\n",
    "    json_df = multiple_json(json_paths)\n",
    "    \n",
    "    # Extract all xml files and return a dataframe\n",
    "    xml_df = multiple_xml(xml_paths)\n",
    "    \n",
    "    \n",
    "    return pd.concat([csv_df, json_df, xml_df],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422eba6-f35e-4776-b4b3-97562e0b0056",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform and Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79055877-ad23-443b-8dd5-39e2cfed9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to capitalise all names\n",
    "'''\n",
    "This function will capitalise all names in a given column\n",
    "Input: series of names\n",
    "Output: series of capitalised names\n",
    "Params: name_col\n",
    "'''\n",
    "def capitalise_names(name_col):\n",
    "    name_list = []\n",
    "    \n",
    "    for name in name_col:\n",
    "        new_name = name.capitalize()\n",
    "        name_list.append(new_name)\n",
    "        \n",
    "    return name_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "650ae7cc-f075-4577-8d82-c89a0371cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert height column from inches to cm\n",
    "'''\n",
    "This function will type cast a column from strings to floats then convert all heights in the given column\n",
    "from inches to cm\n",
    "Input: pandas series\n",
    "Output: series of floats\n",
    "Params: height_col\n",
    "'''\n",
    "def convert_heights(height_col):\n",
    "    # Type cast from string to float\n",
    "    height_col = height_col.astype(float)\n",
    "    \n",
    "    # Convert from inch to cm\n",
    "    height_list = []\n",
    "    for height in height_col:\n",
    "        new_height = round(height*2.54, 2)\n",
    "        height_list.append(new_height)\n",
    "        \n",
    "    return height_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16a64c03-91c4-49b8-a1c0-c68e1173a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert weight column from lbs to kg \n",
    "'''\n",
    "This function will type cast a column from strings to floats then convert all weights in the given column\n",
    "from lbs to kg\n",
    "Input: pandas series\n",
    "Output: series of floats\n",
    "Params: weight_col\n",
    "'''\n",
    "def convert_weights(weight_col):\n",
    "    # Type cast from string to float\n",
    "    weight_col = weight_col.astype(float)\n",
    "    \n",
    "    # Convert from inch to cm\n",
    "    weight_list = []\n",
    "    for weight in weight_col:\n",
    "        new_weight = round(weight/2.204623, 2)\n",
    "        weight_list.append(new_weight)\n",
    "        \n",
    "    return weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f503fb1-587b-4923-a3fd-583071b2d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate a BMI column\n",
    "'''\n",
    "This function will calculate a BMI column as a function of the dataframes height and weight columns\n",
    "Input: pandas dataframe\n",
    "Output: series of floats\n",
    "Params: dataframe\n",
    "'''\n",
    "def calculate_bmi(dataframe):          # Height will be in cm, first converting to meters for bmi calculation\n",
    "    bmi_series = dataframe['Weight'] / (dataframe['Height']/100)**2\n",
    "    \n",
    "    return bmi_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c7c7905-7a61-45c8-a720-9de727f24940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform all data transformations\n",
    "'''\n",
    "This function will convert height and weight columns from strings to floats of cm and kg, repectively.\n",
    "Then calculate a BMI column and change column names to reflect these changes.\n",
    "Input: pandas dataframe\n",
    "Output: pandas dataframe\n",
    "Params: dataframe\n",
    "'''\n",
    "def transform_all(dataframe):\n",
    "    # Transform name column\n",
    "    dataframe['Name'] = capitalise_names(dataframe['Name'])\n",
    "    \n",
    "    # Transform height column\n",
    "    dataframe['Height'] = convert_heights(dataframe['Height'])\n",
    "    \n",
    "    # Transform weight column\n",
    "    dataframe['Weight'] = convert_weights(dataframe['Weight'])\n",
    "    \n",
    "    # Calculate bmi column\n",
    "    dataframe['BMI'] = calculate_bmi(dataframe)\n",
    "    \n",
    "    # Adjust column names\n",
    "    dataframe.columns = ['Name', 'Height (cm)', 'Weight (Kg)', 'BMI']\n",
    "    \n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0afa649a-d024-4e6b-864d-5f1b9d4ce1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to save the resulting dataframe as a csv file\n",
    "'''\n",
    "This function will simply save the resulting dataframe as a csv file in the location provided.\n",
    "Input: file name, path location\n",
    "Output: saved csv file\n",
    "Params: dataframe, file_path\n",
    "'''\n",
    "def load_as_csv(dataframe, file_path):\n",
    "    if file_path.endswith('.csv'):\n",
    "        dataframe.to_csv(file_path)\n",
    "    else:\n",
    "        dataframe.to_csv(file_path + '.csv')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3109f-0e3d-45ef-9baa-8b2962381ab9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Process Log Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489d214-40f7-4a3a-add7-48f447eb5aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7ca64-257a-47b2-8982-95dd9a35bc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4ad3d-8758-46f3-89ec-f444f201081c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5150c400-4cc5-4273-8dc2-d484ebc1b2cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Final Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a65b1-f117-4cad-80fc-9f4be450da80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865f869-9974-42cc-992b-e4e75666875f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
